{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0c82087ebc462a8054960c515940df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c5070c0bbd42419d1a346ede614f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ae5b93cd7a47db947aae6e47611b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "undisputed_best_model = transformers.MBartForConditionalGeneration.from_pretrained(\n",
    "\"ml6team/mbart-large-cc25-cnn-dailymail-nl-finetune\"\n",
    ")\n",
    "\n",
    "tokenizer = transformers.MBartTokenizer.from_pretrained(\"facebook/mbart-large-cc25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(filename):\n",
    "    global df\n",
    "    path = '../data/' + filename\n",
    "    with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "        \n",
    "        number_of_characters = 0\n",
    "        remove_n = []\n",
    "\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "                number_of_characters = number_of_characters + len(line)\n",
    "                remove_n.append(line.strip())\n",
    "\n",
    "    joined_lines = ''.join(remove_n)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    summarization_pipeline = transformers.pipeline(\n",
    "        task=\"summarization\",\n",
    "        model=undisputed_best_model,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    summarization_pipeline.model.config.decoder_start_token_id = tokenizer.lang_code_to_id[\n",
    "        \"nl_XX\"\n",
    "    ]\n",
    "    article = joined_lines  # Dutch\n",
    "    summary = summarization_pipeline(\n",
    "        article,\n",
    "        do_sample=True,\n",
    "        top_p=0.75,\n",
    "        top_k=50,\n",
    "        # num_beams=4,\n",
    "        min_length=50,\n",
    "        early_stopping=True,\n",
    "        truncation=True,\n",
    "    )[0][\"summary_text\"]\n",
    "\n",
    "    \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To dataframe (too long to wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef summarize_all(directory):\\n    # create   df     \\n    data = {\\'File\\': [],\\n        \\'Summary\\': []}\\n    df = pd.DataFrame(data)\\n\\n    for filename in os.listdir(directory):\\n        if filename.endswith(\".txt\"):\\n            print(filename)\\n            output = summarize(filename)\\n            print(output)\\n            values_to_add = {\\'File\\': filename, \\'Summary\\': output}\\n            row_to_add = pd.Series(values_to_add, name=filename)\\n            print(row_to_add)\\n\\n            df = df.append(row_to_add)\\n            print(df.shape)\\n            continue\\n        else:\\n            continue\\n    \\n    return df\\n\\ndirectory = \\'data/\\'\\ndf = summarize_all(directory)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate through the folder\n",
    "'''\n",
    "def summarize_all(directory):\n",
    "    # create   df     \n",
    "    data = {'File': [],\n",
    "        'Summary': []}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            print(filename)\n",
    "            output = summarize(filename)\n",
    "            print(output)\n",
    "            values_to_add = {'File': filename, 'Summary': output}\n",
    "            row_to_add = pd.Series(values_to_add, name=filename)\n",
    "            print(row_to_add)\n",
    "\n",
    "            df = df.append(row_to_add)\n",
    "            print(df.shape)\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return df\n",
    "\n",
    "directory = 'data/'\n",
    "df = summarize_all(directory)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To txt files (too many of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_all(directory):\n",
    "    \n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            print(filename)\n",
    "            output = summarize(filename)\n",
    "            # print(output)\n",
    "            \n",
    "            dest_dir = \"summaries/\"\n",
    "            #with open(dest_dir + filename, 'w') as f:\n",
    "                #f.write(output)\n",
    "                #print(filename)\n",
    "            file = open(dest_dir + filename, 'w', encoding=\"utf-8\")\n",
    "            print(dest_dir)\n",
    "            file.write(output)\n",
    "            print(filename)\n",
    "            file.close()\n",
    "\n",
    "            move_from = \"../\" + directory + filename\n",
    "            move_to = \"bring_back_later/\" + filename\n",
    "            shutil.move(move_from, move_to)\n",
    "            continue\n",
    "        else:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020030602.txt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'summaries/2020030602.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b74a6c8c446f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummarize_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-bfcf704091d8>\u001b[0m in \u001b[0;36msummarize_all\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;31m#f.write(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;31m#print(filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'summaries/2020030602.txt'"
     ]
    }
   ],
   "source": [
    "directory = '../data/'\n",
    "summarize_all(directory)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "573c5f8e4a9de4a29cc2c43f44bd7d1acbfa6c8b3e00d78238142f0788ca6380"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
