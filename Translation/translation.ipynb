{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translates all txt files and insert result into csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "translator.raise_Exception = True\n",
    "\n",
    "# the text may be too long, so we will break it into chunks\n",
    "\n",
    "def get_chunks(s, maxlength, separator):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    while start + maxlength  < len(s) and end != -1:\n",
    "        end = s.rfind(separator, start, start + maxlength + 1)\n",
    "        yield s[start:end]\n",
    "        start = end +1\n",
    "    yield s[start:]\n",
    "\n",
    "output = \"\"\n",
    "\n",
    "def translate_doc(filename):\n",
    "    global df\n",
    "    path = 'data/' + filename\n",
    "    print(path)\n",
    "    with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        # count of characters\n",
    "        number_of_characters = 0\n",
    "        # new list to get rid of \\n\n",
    "        remove_n = []\n",
    "\n",
    "        for line in lines:\n",
    "                number_of_characters = number_of_characters + len(line)\n",
    "                remove_n.append(line.strip())\n",
    "\n",
    "        joined_lines = ''.join(remove_n)\n",
    "        global output\n",
    "\n",
    "        \n",
    "        if number_of_characters > 5000:\n",
    "            \n",
    "            for group in get_chunks(joined_lines, 5000, \".\"):\n",
    "                if len(group) < 5000:\n",
    "                    print(\". option\", len(group))\n",
    "                    group = translator.translate(group)\n",
    "                    #Make list with line lengths:\n",
    "                    output = output + group.text\n",
    "                else:\n",
    "                    for group in get_chunks(joined_lines, 5000, \";\"):\n",
    "                        \n",
    "                        if len(group) < 5000:\n",
    "                            print(\"; option\", len(group))\n",
    "                            group = translator.translate(group)\n",
    "                            #Make list with line lengths:\n",
    "                            output = output + group.text\n",
    "                        else:\n",
    "                            for group in get_chunks(joined_lines, 5000, \",\"):\n",
    "                                # print(len(group))\n",
    "                                if len(group) < 5000:\n",
    "                                    print(\", option\", len(group))\n",
    "                                    group = translator.translate(group)\n",
    "                                    #Make list with line lengths:\n",
    "                                    # [(n, len(n)) for n in chunks]\n",
    "                                    output = output + group.text\n",
    "                    \n",
    "                \n",
    "        else:\n",
    "            print(\"shorter than 5000s\")\n",
    "            output = translator.translate(joined_lines)\n",
    "            output = output.text\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "# iterate through the folder\n",
    "\n",
    "def translate_all(directory):\n",
    "    # create       \n",
    "    data = {'File': [],\n",
    "        'Translation': []}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            translate_doc(filename)\n",
    "            values_to_add = {'File': filename, 'Translation': output}\n",
    "            row_to_add = pd.Series(values_to_add, name=filename)\n",
    "\n",
    "            df = df.append(row_to_add)\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "    time.sleep(2)\n",
    "    return df\n",
    "\n",
    "directory = 'data/'\n",
    "df = translate_all(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/translated.csv', index=False)  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "573c5f8e4a9de4a29cc2c43f44bd7d1acbfa6c8b3e00d78238142f0788ca6380"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
